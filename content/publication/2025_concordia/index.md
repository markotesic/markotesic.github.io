---
authors:
  - Chandler Smith
  - Marwa Abdulhai
  - Manfred Diaz
  - admin
  - Rakshit S. Trivedi
  - Alexander Sasha Vezhnevets
  - Lewis Hammond
  - Jesse Clifton
  - Minsuk Chang
  - Edgar A. Duéñez-Guzmán
  - John P. Agapiou
  - Jayd Matyas
  - Danny Karmon
  - Dylan Hadfield-Menell
  - Natasha Jaques
  - Tim Baarslag
  - Jose Hernandez-Orallo
  - Joel Z. Leibo
  - Concordia contest participants
  
author_notes: []
publication_short: ""
abstract: "Large Language Model (LLM) agents have demonstrated impressive capabilities
for social interaction and are increasingly being deployed in situations where they
might engage with both human and artificial agents. These interactions represent a
critical frontier for LLM-based agents, yet existing evaluation methods fail to mea-
sure how well these capabilities generalize to novel social situations. In this paper,
we introduce a method for evaluating the ability of LLM-based agents to cooperate
in zero-shot, mixed-motive environments using Concordia, a natural language
multi-agent simulation environment. Our method measures general cooperative
intelligence by testing an agent’s ability to identify and exploit opportunities for
mutual gain across diverse partners and contexts. We present empirical results from
the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability
to achieve mutual gains across a suite of diverse scenarios ranging from negotiation
to collective action problems. Our findings reveal significant gaps between current
agent capabilities and the robust generalization required for reliable cooperation,
particularly in scenarios demanding persuasion and norm enforcement."
tags: []
projects: []
slides: ""
url_pdf: "https://arxiv.org/pdf/2512.03318"

links:
#  - icon: twitter
#    icon_pack: fab
#   - name: Website
#     url: https://ai-evaluation-paradigms.github.io
   - name: GitHub
     url: https://github.com/google-deepmind/concordia

publication_types:
  - "1"
image:
  caption: ""
  focal_point: ""
  preview_only: false
  filename: featured.png
summary: "We evaluate the general cooperative intelligence of LLM-based agents in zero-shot, mixed-motive environments using a natural language multi-agent simulation, showing limited generalisation to novel social situations."
url_dataset: ""
url_project: ""
url_source: ""
url_video: ""
publication: "*NeurIPS 2025 Track on Datasets and Benchmarks*"
featured: false
date: 2025-12-03
url_slides: ""
title: "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia"
url_poster: ""
url_code: ""
doi: ""
---
